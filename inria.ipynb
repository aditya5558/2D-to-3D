{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inria.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joEV-zv_RrJJ",
        "colab_type": "text"
      },
      "source": [
        "# Dowloading Inria-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5zGvKl4cdbb",
        "colab_type": "code",
        "outputId": "9c2979ff-e53a-4236-8ec8-3762a9ac1591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_segmentation_disparity.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_persondetection_train.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_persondetection_test.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_poseestimation_train.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_poseestimation_test.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_negatives.tar\n",
        "# !wget https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_video_segmentation.tar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 09:50:28--  https://www.di.ens.fr/willow/research/stereoseg/dataset/inria_stereo_dataset_video_segmentation.tar\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-tar]\n",
            "Saving to: ‘inria_stereo_dataset_video_segmentation.tar’\n",
            "\n",
            "inria_stereo_datase     [<=>                 ] 731.17M  9.30MB/s    in 83s     \n",
            "\n",
            "2020-03-22 09:51:52 (8.84 MB/s) - ‘inria_stereo_dataset_video_segmentation.tar’ saved [766689280]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ovl2pfxR8Oq",
        "colab_type": "text"
      },
      "source": [
        "Decompressing the tar files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o673SasTJS0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar  -xvf inria_stereo_dataset_segmentation.tar\n",
        "# !tar  -xvf inria_stereo_dataset_persondetection_test.tar\n",
        "# !tar -xvf inria_stereo_dataset_poseestimation_train.tar\n",
        "# !tar -xvf inria_stereo_dataset_poseestimation_test.tar\n",
        "# !tar -xvf inria_stereo_dataset_negatives.tar\n",
        "# !tar -xf inria_stereo_dataset_video_segmentation.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGheJT9xSNPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the monocular depth estimation github repo \n",
        "!git clone https://github.com/atapour/monocularDepth-Inference.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3f5jiGuA0Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# folder_path = 'inria_stereo_dataset/segmentation/frames/'\n",
        "folder_path = 'inria_stereo_dataset/segmentation/disparity/'\n",
        "\n",
        "output_path_left = 'left/'\n",
        "output_path_right = 'right/'\n",
        "output_path_disparity = 'segmentation_disparity/'\n",
        "\n",
        "!rm -rf left\n",
        "!rm -rf right\n",
        "!mkdir left\n",
        "!mkdir right\n",
        "!mkdir segmentation_disparity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVoddLLZSfgn",
        "colab_type": "text"
      },
      "source": [
        "Separate left, right images and disparity maps into separate folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBcSnDAaCDuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "for root, subdirs, files in os.walk(folder_path):\n",
        "  print(root, subdirs, files)\n",
        "  for file_ in files:\n",
        "    if file_.endswith('.png'):\n",
        "      os.popen('cp {} {}'.format(root+'/'+file_, output_path_disparity+file_))\n",
        "    if file_.endswith('.jpg'):\n",
        "      os.popen('cp {} {}'.format(root+'/'+file_, output_path_left+file_))\n",
        "    elif file_.endswith('.right'):\n",
        "      os.popen('cp {} {}'.format(root+'/'+file_, output_path_right+file_[:-len('.right')]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq3mcMkkEw5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r segmentation_left '/content/drive/My Drive/Inria_data'\n",
        "# !cp -r segmentation_right '/content/drive/My Drive/Inria_data'\n",
        "# !cp -r checkpoints/ '/content/drive/My Drive/Inria_data/'\n",
        "# !cp -r left '/content/drive/My Drive/Inria_data/Person/test/left'\n",
        "# !cp -r right '/content/drive/My Drive/Inria_data/Person/test/right'\n",
        "# !cp -r left '/content/drive/My Drive/Inria_data/Pose/test/left'\n",
        "# !cp -r right '/content/drive/My Drive/Inria_data/Pose/test/right'\n",
        "# !cp -r left '/content/drive/My Drive/Inria_data/Video/left'\n",
        "# !cp -r right '/content/drive/My Drive/Inria_data/Video/right'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2eoiYKMjCSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf monocular_depth/\n",
        "!mkdir monocular_depth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VOOJqCULipV",
        "colab_type": "code",
        "outputId": "1ad46f9d-18ba-4dc9-90a0-5c6d06fc8420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Download the pretrained model\n",
        "!chmod +x monocularDepth-Inference/download_pretrained_models.sh\n",
        "!monocularDepth-Inference/download_pretrained_models.sh\n",
        "!python monocularDepth-Inference/remove_running_stats.py\n",
        "!python monocularDepth-Inference/run_test.py --data_directory=./left --checkpoints_dir=./checkpoints --results_dir=monocular_depth"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'monocularDepth-Inference/remove_running_stats.py': [Errno 2] No such file or directory\n",
            "python3: can't open file 'monocularDepth-Inference/run_test.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1F_Ad9SjG4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r monocular_depth/ '/content/drive/My Drive/Inria_data/Person/test/'\n",
        "!cp -r monocular_depth/ '/content/drive/My Drive/Inria_data/Video/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DAY-THsS6p-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Evaluating the Generated Depth Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4C2gfVLTEBF",
        "colab_type": "code",
        "outputId": "44d90298-e44d-46a0-a201-ee35237f6c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYypQ_QjTJ3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aIkJc8OZPtY",
        "colab_type": "code",
        "outputId": "41af0f43-6937-47fa-91c9-3167ecc5e4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#evaluation \n",
        "\n",
        "# return error between two images\n",
        "# args:\n",
        "# y_test and y_pred are np.array or list-of-list of same dimensions\n",
        "# specify metric='rmse' or 'log_rmse' to get that metric's value\n",
        "def disparity_eval(y_true, y_pred, metric):\n",
        "    if metric == 'log_rmse':\n",
        "        return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
        "    elif metric == 'rmse':\n",
        "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# example\n",
        "y_true = np.array([[1,0,1],[1,0,0],[0,0,1]])\n",
        "y_pred_good = np.array([[1,0,1],[1,0,0],[1,0,1]])\n",
        "y_pred_bad = np.array([[0,1,1],[0,1,0],[1,0,1]])\n",
        "\n",
        "# pass only one image pair\n",
        "print(f\"closely matched example rmse: {disparity_eval(y_true, y_pred_good, 'rmse')}\")\n",
        "print(f\"closely matched example log_rmse: {disparity_eval(y_true, y_pred_good, 'log_rmse')}\")\n",
        "print(f\"badly matched example rmse: {disparity_eval(y_true, y_pred_bad, 'rmse')}\")\n",
        "print(f\"badly matched example log_rmse: {disparity_eval(y_true, y_pred_bad, 'log_rmse')}\")\n",
        "print(f\"exactly matched example rmse: {disparity_eval(y_true, y_true, 'rmse')}\")\n",
        "print(f\"exactly matched example rmse_log: {disparity_eval(y_true, y_true, 'rmse_log')}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "closely matched example rmse: 0.3333333333333333\n",
            "closely matched example log_rmse: 0.23104906018664842\n",
            "badly matched example rmse: 0.7453559924999298\n",
            "badly matched example log_rmse: 0.5166414047147861\n",
            "exactly matched example rmse: 0.0\n",
            "exactly matched example rmse_log: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k2HaGa_25Bz",
        "colab_type": "code",
        "outputId": "9dcd0984-6b90-4157-b52b-07361580a445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# compute loss b/w disparity-image and depth-map\n",
        "total_rmse, total_log_rmse = 0, 0\n",
        "no_imgs = 0\n",
        "true_folder = '/content/drive/My Drive/Inria_data/Segmentation/disparity/'\n",
        "pred_folder = '/content/drive/My Drive/Inria_data/Segmentation/monocular_depth/'\n",
        "# !unzip -q /content/drive/My\\ Drive/IDL/Segmentation-20200406T024215Z-001.zip  # pgour\n",
        "# true_folder = 'Segmentation/disparity/' # for pgour\n",
        "# pred_folder = 'Segmentation/monocular_depth/' # for pgour\n",
        "\n",
        "\n",
        "for root, subdirs, files in os.walk(true_folder):\n",
        "  for true_file in files:\n",
        "    pred_file = pred_folder + true_file[:-len('.jpg_disparity.png')] + '_depth.png'\n",
        "\n",
        "    img_true = torchvision.transforms.ToTensor()(Image.open(root+true_file)).squeeze()\n",
        "    img_pred = torchvision.transforms.ToTensor()(Image.open(pred_file)).squeeze()\n",
        "    # transform img_pred to be in the format of img_true:\n",
        "    # - scale img_pred to be from 0-1 instead of 0-65535\n",
        "    # - transform 0-1 to 1-0 as white/black are used with reversed meanings by deep3D w.r.t inria's labels\n",
        "    img_pred = 1 - (img_pred.double()/65535)\n",
        "    \n",
        "    no_imgs += 1\n",
        "    total_rmse += disparity_eval(img_true, img_pred,'rmse')\n",
        "    total_log_rmse += disparity_eval(img_true, img_pred,'log_rmse')\n",
        "\n",
        "print('**********************')\n",
        "print('No of images: {}'.format(no_imgs))\n",
        "print('Avg RMSE:     {}'.format(total_rmse/no_imgs))\n",
        "print('Avg Log RMSE:     {}'.format(total_log_rmse/no_imgs))\n",
        "print('**********************')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**********************\n",
            "No of images: 180\n",
            "Avg RMSE:     0.3517795048909582\n",
            "Avg Log RMSE:     0.2270233275741303\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}